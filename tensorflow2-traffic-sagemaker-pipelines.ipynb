{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple SageMaker Pipelines for Traffic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates how to take different actions based on model performance in a SageMaker Pipeline.\n",
    "\n",
    "The steps in this pipeline include:\n",
    "* Preprocessing the California Housing dataset.\n",
    "* Train a TensorFlow2 Artificial Neural Network (ANN) Model.\n",
    "* Evaluate the model performance - mean square error (MSE).\n",
    "* If MSE is higher than threshold, use a Lambda step to send an E-Mail to the Data Science team.\n",
    "* If MSE is lower than threshold, register the model into the Model Registry, and use a Lambda step to deploy the model to SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "#### Add `AmazonSageMakerPipelinesIntegrations` policy\n",
    "\n",
    "The notebook execution role should have policies which enable the notebook to create a Lambda function. The Amazon managed policy `AmazonSageMakerPipelinesIntegrations` can be added to the notebook execution role. \n",
    "\n",
    "The policy description is:\n",
    "\n",
    "```\n",
    "\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"lambda:CreateFunction\",\n",
    "                \"lambda:DeleteFunction\",\n",
    "                \"lambda:InvokeFunction\",\n",
    "                \"lambda:UpdateFunctionCode\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:lambda:*:*:function:*sagemaker*\",\n",
    "                \"arn:aws:lambda:*:*:function:*sageMaker*\",\n",
    "                \"arn:aws:lambda:*:*:function:*SageMaker*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"sqs:CreateQueue\",\n",
    "                \"sqs:SendMessage\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:sqs:*:*:*sagemaker*\",\n",
    "                \"arn:aws:sqs:*:*:*sageMaker*\",\n",
    "                \"arn:aws:sqs:*:*:*SageMaker*\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:PassRole\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:iam::*:role/*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"iam:PassedToService\": [\n",
    "                        \"lambda.amazonaws.com\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "    \n",
    "```\n",
    "\n",
    "#### Add inline policy to enable creation of IAM role required for the Lambda Function\n",
    "\n",
    "The notebook execution role should have an inline policy which enable the notebook to create the IAM role required for the Lambda function. An inline policy can be added to the notebook execution role. \n",
    "\n",
    "The policy description is:\n",
    "\n",
    "```\n",
    "{\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"iam:GetRole\",\n",
    "                \"iam:CreateRole\",\n",
    "                \"iam:AttachRolePolicy\"\n",
    "            ],\n",
    "            \"Resource\": \"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /opt/conda/lib/python3.7/site-packages (2.104.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.105.0.tar.gz (567 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.9/567.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: attrs<22,>=20.3.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.20.21 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.24.27)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.19.5)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (3.19.4)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: smdebug_rulesconfig==1.0.1 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (4.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from sagemaker) (20.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from sagemaker) (1.3.5)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.7/site-packages (from sagemaker) (0.2.9)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.27 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.27.27)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0,>=1.20.21->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->sagemaker) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.5 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (1.7.6.5)\n",
      "Requirement already satisfied: dill>=0.3.5.1 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.13 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.13)\n",
      "Requirement already satisfied: pox>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.27->boto3<2.0,>=1.20.21->sagemaker) (1.26.10)\n",
      "Building wheels for collected packages: sagemaker\n",
      "  Building wheel for sagemaker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sagemaker: filename=sagemaker-2.105.0-py2.py3-none-any.whl size=783586 sha256=4090825bbc3996c948b11918f25bbb71660f131578c2f0d4297cdfddedd71cd0\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/fc/34/94a8645919501020cf6fc1b5a0704c8681cc707db68ee61754\n",
      "Successfully built sagemaker\n",
      "Installing collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.104.0\n",
      "    Uninstalling sagemaker-2.104.0:\n",
      "      Successfully uninstalled sagemaker-2.104.0\n",
      "Successfully installed sagemaker-2.105.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"<YOUR BUCKKET NAME HERE>\"\n",
    "\n",
    "train_instance_type='ml.m5.12xlarge'      # The type of EC2 instance which will be used for training\n",
    "deploy_instance_type='ml.m5.4xlarge'     # The type of EC2 instance which will be used for deployment\n",
    "\n",
    "'''\n",
    "we can use the train and validation path as stated above \n",
    "or you can \n",
    "just rearrange data and use a single path like below\n",
    "'''\n",
    "training_data_uri=\"s3://{}\".format(bucket)\n",
    "test_data_uri=f\"{training_data_uri}/test\"\n",
    "\n",
    "sess = boto3.Session()\n",
    "sm = sess.client(\"sagemaker\")\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(boto_session=sess)\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "#model_package_group_name = \"TF2-California-Housing\"  # Model name in model registry\n",
    "prefix = \"tf2-traffic-pipelines\"\n",
    "#pipeline_name = \"TF2CaliforniaHousingPipeline\"  # SageMaker Pipeline name\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model step\n",
    "In the second step, the train and validation output from the precious processing step are used to train a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "import time\n",
    "\n",
    "# Where to store the trained model\n",
    "model_path = f\"s3://{bucket}/{prefix}/model/\"\n",
    "\n",
    "#hyperparameters = {\"epochs\": training_epochs}\n",
    "tensorflow_version = \"2.4.1\"\n",
    "python_version = \"py37\"\n",
    "\n",
    "tf2_estimator = TensorFlow(\n",
    "  base_job_name='tensorflow-pssummit-traffic-class',\n",
    "  entry_point=\"tfModelCode.py\",             # Your entry script\n",
    "  role=role,\n",
    "  framework_version=tensorflow_version,               # TensorFlow's version\n",
    "  py_version=python_version,\n",
    "  output_path=model_path,\n",
    "  instance_count=1, \n",
    "  instance_type=train_instance_type,\n",
    ")\n",
    "\n",
    "#print(\"Training ...\")\n",
    "#estimator_tf.fit(training_data_uri,logs=False)\n",
    "\n",
    "# Use the tf2_estimator in a Sagemaker pipelines ProcessingStep.\n",
    "# NOTE how the input to the training job directly references the output of the previous step.\n",
    "step_train_model = TrainingStep(\n",
    "    name=\"Train-Traffic-Model\",\n",
    "    estimator=tf2_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=training_data_uri,\n",
    "        ),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://agm-dov-temp'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model step\n",
    "When a model is trained, it's common to evaluate the model on unseen data before registering it with the model registry. This ensures the model registry isn't cluttered with poorly performing model versions. To evaluate the model, create a ScriptProcessor object and use it in a ProcessingStep.\n",
    "\n",
    "**Note** that a separate preprocessed test dataset is used to evaluate the model, and not the output of the processing step. This is only for demo purposes, to ensure the second run of the pipeline creates a model with better performance. In a real-world scenario, the test output of the processing step would be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting evaluate.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile evaluate.py\n",
    "\n",
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import tarfile\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "test_dir = '/opt/ml/processing/test'\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    install(\"tensorflow==2.4.1\")\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path, \"r:gz\") as tar:\n",
    "        tar.extractall(\"./model\")\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "\n",
    "    # Function for generating batches\n",
    "    def get_batches(dirname, gen=image.ImageDataGenerator(), shuffle=False, batch_size=32, class_mode='categorical',\n",
    "                    target_size=(250,250)):\n",
    "        return gen.flow_from_directory(dirname, target_size=target_size,\n",
    "                class_mode=class_mode, shuffle=shuffle, batch_size=batch_size)\n",
    "\n",
    "    # Load all data\n",
    "    def get_data(path, target_size=(250,250)):\n",
    "        batches = get_batches(path, shuffle=False, batch_size=1, class_mode=None, target_size=target_size)\n",
    "        return np.concatenate([batches.next() for i in range(batches.samples)])\n",
    "    \n",
    "    \n",
    "    model = tf.keras.models.load_model(\"./model/tf000000001/1\")\n",
    "    test_path = \"/opt/ml/processing/test/\"\n",
    "    \n",
    "    #LOAD TEST DATA\n",
    "    test_gen=get_batches(test_dir, shuffle=False, batch_size=32).classes\n",
    "    test_labels=tf.keras.utils.to_categorical(test_gen)\n",
    "    test_img=get_data(test_dir)\n",
    "\n",
    "    scores = model.evaluate(test_img, test_labels, verbose=2)\n",
    "    print(\"\\nTest Eval :\", scores)\n",
    "\n",
    "    # Available metrics to add to model: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\n",
    "    report_dict = {\n",
    "        \"classification_metrics\": {\n",
    "            \"acc\": {\"value\": scores},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "framework_version = \"1.0-1\"\n",
    "\n",
    "# Create SKLearnProcessor object.\n",
    "# The object contains information about what container to use, what instance type etc.\n",
    "evaluate_model_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    base_job_name=\"tf2-traffic-evaluate\",\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "# Create a PropertyFile\n",
    "# A PropertyFile is used to be able to reference outputs from a processing step, for instance to use in a condition step.\n",
    "# For more information, visit https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-propertyfile.html\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "# Use the evaluate_model_processor in a Sagemaker pipelines ProcessingStep.\n",
    "step_evaluate_model = ProcessingStep(\n",
    "    name=\"Evaluate-Traffic-Model\",\n",
    "    processor=evaluate_model_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=test_data_uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"evaluate.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send E-Mail Lambda Step\n",
    "\n",
    "When defining the `LambdaStep`, the SageMaker Lambda helper class provides helper functions for creating the Lambda function. Users can either use the `lambda_func` argument to provide the function ARN to an already deployed Lambda function OR use the `Lambda` class to create a Lambda function by providing a script, function name and role for the Lambda function.\n",
    "\n",
    "When passing inputs to the Lambda, the `inputs` argument can be used and within the Lambda function's handler, the `event` argument can be used to retrieve the inputs.\n",
    "\n",
    "The dictionary response from the Lambda function is parsed through the `LambdaOutput` objects provided to the `outputs` argument. The `output_name` in `LambdaOutput` corresponds to the dictionary key in the Lambda's return dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Lambda function\n",
    "\n",
    "Users can choose the leverage the Lambda helper class to create a Lambda function and provide that function object to the `LambdaStep`. Alternatively, users can use a pre-deployed Lambda function and provide the function ARN to the `Lambda` helper class in the lambda step.\n",
    "\n",
    "Here, If the MSE is lower than threshold, an E-Mail will be sent to Data Science team.\n",
    "\n",
    "Note that the E-Mail sending part is left for you to implement by the framework you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing send_email_lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile send_email_lambda.py\n",
    "\n",
    "\"\"\"\n",
    "This Lambda function sends an E-Mail to the Data Science team with the MSE from model evaluation step. \n",
    "The evaluation.json location in S3 is provided via the `event` argument\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "s3_client = client = boto3.client(\"s3\")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    print(f\"Received Event: {event}\")\n",
    "\n",
    "    evaluation_s3_uri = event[\"evaluation_s3_uri\"]\n",
    "    path_parts = evaluation_s3_uri.replace(\"s3://\", \"\").split(\"/\")\n",
    "    bucket = path_parts.pop(0)\n",
    "    key = \"/\".join(path_parts)\n",
    "\n",
    "    content = s3_client.get_object(Bucket=bucket, Key=key)\n",
    "    text = content[\"Body\"].read().decode()\n",
    "    evaluation_json = json.loads(text)\n",
    "    mse = evaluation_json[\"regression_metrics\"][\"mse\"][\"value\"]\n",
    "\n",
    "    subject_line = \"Please check high MSE ({}) detected on model evaluation\".format(mse)\n",
    "    print(f\"Sending E-Mail to Data Science Team with subject line: {subject_line}\")\n",
    "\n",
    "    # TODO - ADD YOUR CODE TO SEND EMAIL...\n",
    "\n",
    "    return {\"statusCode\": 200, \"body\": json.dumps(\"E-Mail Sent Successfully\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IAM Role\n",
    "\n",
    "The Lambda function needs an IAM role that will allow it to read the `evaluation.json` from S3. The role ARN must be provided in the `LambdaStep`.\n",
    "\n",
    "A helper function in `iam_helper.py` is available to create the Lambda function role. Please note that the role uses the Amazon managed policy - `AmazonS3ReadOnlyAccess`. This should be replaced with an IAM policy with the least privileges as per AWS IAM best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 30 seconds for the IAM role to propagate\n"
     ]
    }
   ],
   "source": [
    "from iam_helper import create_s3_lambda_role\n",
    "\n",
    "lambda_role = create_s3_lambda_role(\"send-email-to-ds-team-lambda-role\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Lambda Function step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "evaluation_s3_uri = \"{}/evaluation.json\".format(\n",
    "    step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "send_email_lambda_function_name = \"sagemaker-send-email-to-ds-team-lambda-\" + current_time\n",
    "\n",
    "send_email_lambda_function = Lambda(\n",
    "    function_name=send_email_lambda_function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"send_email_lambda.py\",\n",
    "    handler=\"send_email_lambda.lambda_handler\",\n",
    ")\n",
    "\n",
    "step_higher_mse_send_email_lambda = LambdaStep(\n",
    "    name=\"Send-Email-To-DS-Team\",\n",
    "    lambda_func=send_email_lambda_function,\n",
    "    inputs={\"evaluation_s3_uri\": evaluation_s3_uri},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register model step\n",
    "If the trained model meets the model performance requirements a new model version is registered with the model registry for further analysis. To attach model metrics to the model version, create a [`ModelMetrics`](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html) object using the evaluation report created in the evaluation step. Then, create the RegisterModel step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "evaluation_s3_uri = \"{}/evaluation.json\".format(\n",
    "    step_evaluate_model.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    ")\n",
    "\n",
    "model_package_group_name = \"TF2-Traffic\"  # Model name in model registry\n",
    "\n",
    "# Create ModelMetrics object using the evaluation report from the evaluation step\n",
    "# A ModelMetrics object contains metrics captured from a model.\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=evaluation_s3_uri,\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a RegisterModel step, which registers the model with Sagemaker Model Registry.\n",
    "step_register_model = RegisterModel(\n",
    "    name=\"Register--Traffic-Model\",\n",
    "    estimator=tf2_estimator,\n",
    "    model_data=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.m5.large\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "The model is created and the name of the model is provided to the Lambda function for deployment. The `CreateModelStep` dynamically assigns a name to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import CreateModelStep\n",
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "\n",
    "model = TensorFlowModel(\n",
    "    role=role,\n",
    "    model_data=step_train_model.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    framework_version=tensorflow_version,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "step_create_model = CreateModelStep(\n",
    "    name=\"Create-California-Housing-Model\",\n",
    "    model=model,\n",
    "    inputs=sagemaker.inputs.CreateModelInput(instance_type=\"ml.m5.large\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model to SageMaker Endpoint Lambda Step\n",
    "\n",
    "When defining the `LambdaStep`, the SageMaker Lambda helper class provides helper functions for creating the Lambda function. Users can either use the `lambda_func` argument to provide the function ARN to an already deployed Lambda function OR use the `Lambda` class to create a Lambda function by providing a script, function name and role for the Lambda function.\n",
    "\n",
    "When passing inputs to the Lambda, the `inputs` argument can be used and within the Lambda function's handler, the `event` argument can be used to retrieve the inputs.\n",
    "\n",
    "The dictionary response from the Lambda function is parsed through the `LambdaOutput` objects provided to the `outputs` argument. The `output_name` in `LambdaOutput` corresponds to the dictionary key in the Lambda's return dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Lambda function\n",
    "\n",
    "Here, the Lambda Function will deploy the model to SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing deploy_model_lambda.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy_model_lambda.py\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This Lambda function deploys the model to SageMaker Endpoint. \n",
    "If Endpoint exists, then Endpoint will be updated with new Endpoint Config.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "import time\n",
    "\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "\n",
    "    print(f\"Received Event: {event}\")\n",
    "\n",
    "    current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "    endpoint_instance_type = event[\"endpoint_instance_type\"]\n",
    "    model_name = event[\"model_name\"]\n",
    "    endpoint_config_name = \"{}-{}\".format(event[\"endpoint_config_name\"], current_time)\n",
    "    endpoint_name = event[\"endpoint_name\"]\n",
    "\n",
    "    # Create Endpoint Configuration\n",
    "    create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name,\n",
    "        ProductionVariants=[\n",
    "            {\n",
    "                \"InstanceType\": endpoint_instance_type,\n",
    "                \"InitialVariantWeight\": 1,\n",
    "                \"InitialInstanceCount\": 1,\n",
    "                \"ModelName\": model_name,\n",
    "                \"VariantName\": \"AllTraffic\",\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    print(f\"create_endpoint_config_response: {create_endpoint_config_response}\")\n",
    "\n",
    "    # Check if an endpoint exists. If no - Create new endpoint, if yes - Update existing endpoint\n",
    "    list_endpoints_response = sm_client.list_endpoints(\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "        NameContains=endpoint_name,\n",
    "    )\n",
    "    print(f\"list_endpoints_response: {list_endpoints_response}\")\n",
    "\n",
    "    if len(list_endpoints_response[\"Endpoints\"]) > 0:\n",
    "        print(\"Updating Endpoint with new Endpoint Configuration\")\n",
    "        update_endpoint_response = sm_client.update_endpoint(\n",
    "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "        print(f\"update_endpoint_response: {update_endpoint_response}\")\n",
    "    else:\n",
    "        print(\"Creating Endpoint\")\n",
    "        create_endpoint_response = sm_client.create_endpoint(\n",
    "            EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "        print(f\"create_endpoint_response: {create_endpoint_response}\")\n",
    "\n",
    "    return {\"statusCode\": 200, \"body\": json.dumps(\"Endpoint Created Successfully\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IAM Role\n",
    "\n",
    "The Lambda function needs an IAM role that will allow it to deploy a SageMaker Endpoint. The role ARN must be provided in the `LambdaStep`.\n",
    "\n",
    "A helper function in `iam_helper.py` is available to create the Lambda function role. Please note that the role uses the Amazon managed policy - `AmazonSageMakerFullAccess`. This should be replaced with an IAM policy with the least privileges as per AWS IAM best practices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting 30 seconds for the IAM role to propagate\n"
     ]
    }
   ],
   "source": [
    "from iam_helper import create_sagemaker_lambda_role\n",
    "\n",
    "lambda_role = create_sagemaker_lambda_role(\"deploy-model-lambda-role\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.lambda_step import LambdaStep\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "endpoint_config_name = \"tf2-california-housing-endpoint-config\"\n",
    "endpoint_name = \"tf2-california-housing-endpoint-\" + current_time\n",
    "\n",
    "deploy_model_lambda_function_name = \"sagemaker-deploy-model-lambda-\" + current_time\n",
    "\n",
    "deploy_model_lambda_function = Lambda(\n",
    "    function_name=deploy_model_lambda_function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"deploy_model_lambda.py\",\n",
    "    handler=\"deploy_model_lambda.lambda_handler\",\n",
    ")\n",
    "\n",
    "step_lower_mse_deploy_model_lambda = LambdaStep(\n",
    "    name=\"Deploy-California-Housing-Model-To-Endpoint\",\n",
    "    lambda_func=deploy_model_lambda_function,\n",
    "    inputs={\n",
    "        \"model_name\": step_create_model.properties.ModelName,\n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "        \"endpoint_instance_type\": endpoint_instance_type,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy condition step\n",
    "Adding conditions to the pipeline is done with a ConditionStep.\n",
    "In this case, we only want to register the new model version with the model registry if the new model meets an accuracy condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "# Create accuracy condition to ensure the model meets performance requirements.\n",
    "# Models with a test accuracy lower than the condition will not be registered with the model registry.\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_evaluate_model.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=accuracy_mse_threshold,\n",
    ")\n",
    "\n",
    "# Create a Sagemaker Pipelines ConditionStep, using the condition above.\n",
    "# Enter the steps to perform if the condition returns True / False.\n",
    "step_cond = ConditionStep(\n",
    "    name=\"MSE-Lower-Than-Threshold-Condition\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_register_model, step_create_model, step_lower_mse_deploy_model_lambda],\n",
    "    else_steps=[step_higher_mse_send_email_lambda],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Creation: Orchestrate all steps\n",
    "\n",
    "Now that all pipeline steps are created, a pipeline is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# Create a Sagemaker Pipeline.\n",
    "# Each parameter for the pipeline must be set as a parameter explicitly when the pipeline is created.\n",
    "# Also pass in each of the steps created above.\n",
    "# Note that the order of execution is determined from each step's dependencies on other steps,\n",
    "# not on the order they are passed in below.\n",
    "pipeline = Pipeline(\n",
    "    name=\"mytestpipeline\",\n",
    "#    parameters=[\n",
    "#        input_data,\n",
    "#        training_epochs,\n",
    "#        accuracy_mse_threshold,\n",
    "#        endpoint_instance_type,\n",
    "#    ],\n",
    "    #steps=[step_preprocess_data, step_train_model, step_evaluate_model, step_cond],\n",
    "    steps=[step_train_model,step_evaluate_model,step_register_model],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List the execution steps to check out the status and artifacts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'Train-Traffic-Model',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.4.1-cpu-py37',\n",
       "     'EnableSageMakerMetricsTimeSeries': True},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-650687152614/tf2-traffic-pipelines/model/'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'VolumeSizeInGB': 30,\n",
       "     'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.m5.12xlarge'},\n",
       "    'RoleArn': 'arn:aws:iam::650687152614:role/service-role/AmazonSageMaker-ExecutionRole-20220301T162062',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': 's3://agm-scratch',\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ChannelName': 'train'}],\n",
       "    'HyperParameters': {'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-650687152614/Train-Traffic-Model-c768e4aeeaa44743acd0b1c6b3d49d54/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"tfModelCode.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"us-east-1\"',\n",
       "     'model_dir': '\"s3://sagemaker-us-east-1-650687152614/tf2-traffic-pipelines/model/Train-Traffic-Model-c768e4aeeaa44743acd0b1c6b3d49d54/model\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-650687152614/tf2-traffic-pipelines/model/',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1661193956',\n",
       "      'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "      'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-650687152614/tf2-traffic-pipelines/model/'}}},\n",
       "  {'Name': 'Evaluate-Traffic-Model',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.m5.large',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.0-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/evaluate.py']},\n",
       "    'RoleArn': 'arn:aws:iam::650687152614:role/service-role/AmazonSageMaker-ExecutionRole-20220301T162062',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Steps.Train-Traffic-Model.ModelArtifacts.S3ModelArtifacts'},\n",
       "       'LocalPath': '/opt/ml/processing/model',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'input-2',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://agm-scratch/test',\n",
       "       'LocalPath': '/opt/ml/processing/test',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-650687152614/Evaluate-Traffic-Model-ede37c52c44b291e47fe15515d85fbf7/input/code/evaluate.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'evaluation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-650687152614/Evaluate-Traffic-Model-ede37c52c44b291e47fe15515d85fbf7/output/evaluation',\n",
       "        'LocalPath': '/opt/ml/processing/evaluation',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'PropertyFiles': [{'PropertyFileName': 'EvaluationReport',\n",
       "     'OutputName': 'evaluation',\n",
       "     'FilePath': 'evaluation.json'}]},\n",
       "  {'Name': 'Register--Traffic-Model-RegisterModel',\n",
       "   'Type': 'RegisterModel',\n",
       "   'Arguments': {'ModelPackageGroupName': 'TF2-Traffic',\n",
       "    'ModelMetrics': {'ModelQuality': {'Statistics': {'ContentType': 'application/json',\n",
       "       'S3Uri': 's3://sagemaker-us-east-1-650687152614/Evaluate-Traffic-Model-ede37c52c44b291e47fe15515d85fbf7/output/evaluation/evaluation.json'}},\n",
       "     'Bias': {},\n",
       "     'Explainability': {}},\n",
       "    'InferenceSpecification': {'Containers': [{'Image': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.4.1-cpu',\n",
       "       'ModelDataUrl': {'Get': 'Steps.Train-Traffic-Model.ModelArtifacts.S3ModelArtifacts'}}],\n",
       "     'SupportedContentTypes': ['text/csv'],\n",
       "     'SupportedResponseMIMETypes': ['text/csv'],\n",
       "     'SupportedRealtimeInferenceInstanceTypes': ['ml.m5.large',\n",
       "      'ml.m5.xlarge'],\n",
       "     'SupportedTransformInstanceTypes': ['ml.m5.xlarge']},\n",
       "    'ModelApprovalStatus': 'PendingManualApproval'}}]}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:650687152614:pipeline/mytestpipeline',\n",
       " 'ResponseMetadata': {'RequestId': 'b70ece93-b7d0-45ac-b833-f9d71b52e5f0',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'b70ece93-b7d0-45ac-b833-f9d71b52e5f0',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '82',\n",
       "   'date': 'Mon, 22 Aug 2022 18:45:59 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute pipeline using the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for pipeline to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize SageMaker Pipeline - MSE lower than the threshold\n",
    "In SageMaker Studio, choose `SageMaker Components and registries` in the left pane and under `Pipelines`, click the pipeline that was created. Then all pipeline executions are shown, and the one just created should have a status of `Succeded`. Selecting that execution, the different pipeline steps can be tracked as they execute.\n",
    "\n",
    "You can see that the `Register-California-Housing-Model` step was executed.\n",
    "\n",
    "![](images/pipeline_run_1_mse_lower_than_threshold.png \"Pipeline - MSE lower than the threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a pipeline with 2 epochs to trigger the `send-email-to-ds-team-lambda` Lambda Function\n",
    "\n",
    "\n",
    "Run the pipeline again, but this time, with only 2 epochs and a lower MSE Threshold of 0.2. This will result in a higher MSE value on model evaluation, and will cause the `send-email-to-ds-team-lambda` Lambda Function to be triggered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute pipeline with explicit parameters\n",
    "execution = pipeline.start(parameters=dict(TrainingEpochs=2, AccuracyMseThreshold=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize SageMaker Pipeline - MSE higher than the threshold\n",
    "In SageMaker Studio, choose `SageMaker Components and registries` in the left pane and under `Pipelines`, click the pipeline that was created. Then all pipeline executions are shown, and the one just created should have a status of `Succeded`. Selecting that execution, the different pipeline steps can be tracked as they execute.\n",
    "\n",
    "You can see that the `Send-Email-To-DS-Team` step was executed.\n",
    "\n",
    "![](images/pipeline_run_1_mse_higher_than_threshold.png \"Pipeline - MSE higher than the threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop / Close the Endpoint\n",
    "You should delete the endpoint before you close the notebook if you don't need to keep the endpoint running for serving real-time predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"sagemaker\")\n",
    "client.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the model registry and the pipeline to keep the studio environment tidy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_model_package_group(sm_client, package_group_name):\n",
    "    try:\n",
    "        model_versions = sm_client.list_model_packages(ModelPackageGroupName=package_group_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "        return\n",
    "\n",
    "    for model_version in model_versions[\"ModelPackageSummaryList\"]:\n",
    "        try:\n",
    "            sm_client.delete_model_package(ModelPackageName=model_version[\"ModelPackageArn\"])\n",
    "        except Exception as e:\n",
    "            print(\"{} \\n\".format(e))\n",
    "        time.sleep(0.5)  # Ensure requests aren't throttled\n",
    "\n",
    "    try:\n",
    "        sm_client.delete_model_package_group(ModelPackageGroupName=package_group_name)\n",
    "        print(\"{} model package group deleted\".format(package_group_name))\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "    return\n",
    "\n",
    "\n",
    "def delete_sagemaker_pipeline(sm_client, pipeline_name):\n",
    "    try:\n",
    "        sm_client.delete_pipeline(\n",
    "            PipelineName=pipeline_name,\n",
    "        )\n",
    "        print(\"{} pipeline deleted\".format(pipeline_name))\n",
    "    except Exception as e:\n",
    "        print(\"{} \\n\".format(e))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_model_package_group(client, model_package_group_name)\n",
    "delete_sagemaker_pipeline(client, pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete the Lambda functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_email_lambda_function.delete()\n",
    "deploy_model_lambda_function.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
